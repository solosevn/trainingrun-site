{
  "formula_version": "1.0",
  "checksum": "5d342be071efc7f0041efb7c5c4c8bd13df08b8a9ac926ff4b4da2d48aa21fd8",
  "weights": {
    "swebench_verified": 0.17,
    "swe_rebench": 0.13,
    "livecodebench": 0.15,
    "bigcodebench": 0.1,
    "terminal_bench_hard": 0.12,
    "swebench_pro": 0.08,
    "scicode": 0.15,
    "arena_code_elo": 0.1
  },
  "dates": [
    "2026-01-01",
    "2026-01-02",
    "2026-01-03",
    "2026-01-04",
    "2026-01-05",
    "2026-01-06",
    "2026-01-07",
    "2026-01-08",
    "2026-01-09",
    "2026-01-10",
    "2026-01-11",
    "2026-01-12",
    "2026-01-13",
    "2026-01-14",
    "2026-01-15",
    "2026-01-16",
    "2026-01-17",
    "2026-01-18",
    "2026-01-19",
    "2026-01-20",
    "2026-01-21",
    "2026-01-22",
    "2026-01-23",
    "2026-01-24",
    "2026-01-25",
    "2026-01-26",
    "2026-01-27",
    "2026-01-28",
    "2026-01-29",
    "2026-01-30",
    "2026-01-31",
    "2026-02-01",
    "2026-02-02",
    "2026-02-03",
    "2026-02-04",
    "2026-02-05",
    "2026-02-06",
    "2026-02-07",
    "2026-02-08",
    "2026-02-09",
    "2026-02-10",
    "2026-02-11",
    "2026-02-12",
    "2026-02-13",
    "2026-02-14",
    "2026-02-15",
    "2026-02-16",
    "2026-02-17",
    "2026-02-15",
    "2026-02-15",
    "2026-02-15",
    "2026-02-15",
    "2026-02-15",
    "2026-02-15",
    "2026-02-19",
    "2026-02-20",
    "2026-02-21",
    "2026-02-22"
  ],
  "models": [
    {
      "name": "Claude Opus 4.6",
      "company": "Anthropic",
      "rank": 2,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        48.6,
        48.9,
        49.5,
        49.6,
        49.5,
        48.9,
        48.8,
        47.9,
        47.9,
        49.9,
        49.6,
        49.6,
        49.6,
        49.23,
        48.77,
        49.02,
        48.91,
        48.86,
        48.81,
        64.92,
        71.38,
        76.58,
        76.58
      ],
      "pillar_scores": {
        "issue_resolution": 96.1,
        "code_generation": null,
        "agentic_coding": 93.1,
        "scientific": null,
        "human_preference": 100
      },
      "source_count": 7,
      "raw_data": {
        "swebench_verified_pct": 67.6,
        "swe_rebench_pass1": 47.1,
        "livecodebench_pct": 71.8,
        "bigcodebench_pct": 34.8,
        "terminalbench_hard_pct": 38.0,
        "swebench_pro_pct": 45.89,
        "scicode_pct": null,
        "arena_code_elo": 1567
      }
    },
    {
      "name": "Claude Sonnet 4.5",
      "company": "Anthropic",
      "rank": 4,
      "scores": [
        60.4,
        59.7,
        58.7,
        58.8,
        58.8,
        59.3,
        59.8,
        59.6,
        59.5,
        59.5,
        59.5,
        59.7,
        60.4,
        60.5,
        60.6,
        60.5,
        60,
        59.7,
        59.3,
        59.4,
        59.9,
        59.4,
        59,
        59.1,
        60.3,
        59.7,
        59.2,
        59,
        58.9,
        58.6,
        58.8,
        58.3,
        57.4,
        57.7,
        57.4,
        57.7,
        57.7,
        58,
        57.7,
        57.3,
        56.9,
        57.1,
        56.3,
        56.5,
        59.5,
        59.9,
        60,
        60,
        60.23,
        60.33,
        60.52,
        60.69,
        60.89,
        61.09,
        62.77,
        62.77,
        62.82,
        62.82
      ],
      "pillar_scores": {
        "issue_resolution": 89.3,
        "code_generation": 58.7,
        "agentic_coding": 78.5,
        "scientific": null,
        "human_preference": 88.7
      },
      "source_count": 6,
      "raw_data": {
        "swebench_verified_pct": 52.8,
        "swe_rebench_pass1": 48.5,
        "livecodebench_pct": 73.1,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 35.5,
        "swebench_pro_pct": 42.7,
        "scicode_pct": null,
        "arena_code_elo": 1390
      }
    },
    {
      "name": "Gemini 3 Pro",
      "company": "Google",
      "rank": 3,
      "scores": [
        55.7,
        54.9,
        54.9,
        55.1,
        54.6,
        55.3,
        54.9,
        54.5,
        55.4,
        55.9,
        56.2,
        56.3,
        55.8,
        54.7,
        55.1,
        55.8,
        55.7,
        55.5,
        55.5,
        55.4,
        55.9,
        56.5,
        56.8,
        56.3,
        56.5,
        56.5,
        56.4,
        55.5,
        55,
        55.7,
        56,
        56,
        56.5,
        56.5,
        55.4,
        55.1,
        54.6,
        54.8,
        55.2,
        54.5,
        54.2,
        54.7,
        54.6,
        54.6,
        55.3,
        55,
        54.8,
        54.8,
        54.58,
        54.49,
        54.69,
        54.3,
        54.23,
        54.16,
        55.92,
        67.4,
        65.6,
        65.6
      ],
      "pillar_scores": {
        "issue_resolution": 93.3,
        "code_generation": null,
        "agentic_coding": 90.3,
        "scientific": null,
        "human_preference": 92.5
      },
      "source_count": 7,
      "raw_data": {
        "swebench_verified_pct": 53.6,
        "swe_rebench_pass1": 51.7,
        "livecodebench_pct": 74.2,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 32.6,
        "swebench_pro_pct": 34.63,
        "scicode_pct": 1.5,
        "arena_code_elo": 1205.0
      }
    },
    {
      "name": "GPT-5.2",
      "company": "OpenAI",
      "rank": 1,
      "scores": [
        52.8,
        53.3,
        54.1,
        53.8,
        53.6,
        53.6,
        53.1,
        52.3,
        52.5,
        51.7,
        51.6,
        52.1,
        52.3,
        51.9,
        52,
        52.1,
        52.8,
        53.4,
        53.7,
        53.8,
        53.4,
        53.9,
        54.3,
        54.4,
        54.1,
        54.4,
        54.2,
        54.4,
        54.8,
        54.6,
        54.6,
        54.3,
        53.8,
        53.7,
        53.4,
        53.9,
        53.8,
        53.6,
        53.4,
        53.5,
        53.6,
        53.5,
        52.8,
        52.6,
        53.2,
        53.3,
        52.8,
        52.8,
        52.66,
        53.11,
        53,
        52.88,
        53.02,
        53.16,
        54.88,
        77.8,
        77.51,
        77.51
      ],
      "pillar_scores": {
        "issue_resolution": 94.4,
        "code_generation": null,
        "agentic_coding": 75.8,
        "scientific": null,
        "human_preference": 94
      },
      "source_count": 7,
      "raw_data": {
        "swebench_verified_pct": 69.0,
        "swe_rebench_pass1": 51.7,
        "livecodebench_pct": 75.8,
        "bigcodebench_pct": 35.5,
        "terminalbench_hard_pct": 49.6,
        "swebench_pro_pct": 29.94,
        "scicode_pct": null,
        "arena_code_elo": 1336.0
      }
    },
    {
      "name": "DeepSeek V3.2",
      "company": "DeepSeek",
      "rank": 7,
      "scores": [
        39.7,
        40.2,
        40.2,
        39.9,
        39.9,
        39.9,
        40.2,
        40.1,
        40.6,
        40.5,
        40.9,
        40.3,
        40.6,
        40.4,
        41.1,
        40.9,
        40.9,
        41.4,
        41.3,
        41.4,
        41,
        41.3,
        40.9,
        40.8,
        40.8,
        40.4,
        40.5,
        40.9,
        41.2,
        41.7,
        42.1,
        41.8,
        42,
        41.5,
        41.5,
        41,
        41.2,
        41.3,
        41.2,
        41,
        40.9,
        39.7,
        40,
        40,
        40,
        40.2,
        40.2,
        40.2,
        40.17,
        39.98,
        40.19,
        39.96,
        40.02,
        40.08,
        54.11,
        41.65,
        43.73,
        43.73
      ],
      "pillar_scores": {
        "issue_resolution": 73.5,
        "code_generation": null,
        "agentic_coding": 43.3,
        "scientific": null,
        "human_preference": 87.7
      },
      "source_count": 5,
      "raw_data": {
        "swebench_verified_pct": 60.0,
        "swe_rebench_pass1": 37.5,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 39.6,
        "swebench_pro_pct": 15.56,
        "scicode_pct": null,
        "arena_code_elo": 1286.0
      }
    },
    {
      "name": "Qwen3-Coder",
      "company": "Alibaba",
      "rank": 11,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        53.47,
        12.94,
        27.86,
        27.86
      ],
      "pillar_scores": {},
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 55.4,
        "swebench_pro_pct": 38.7,
        "arena_code_elo": 1282.0
      }
    },
    {
      "name": "Grok 4.20",
      "company": "xAI",
      "rank": 9,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        52.83,
        27.52,
        34.1,
        34.1
      ],
      "pillar_scores": {},
      "source_count": 4,
      "raw_data": {
        "swe_rebench_pass1": 37.5,
        "livecodebench_pct": 55.9,
        "bigcodebench_pct": 31.8,
        "terminalbench_hard_pct": 27.2
      }
    },
    {
      "name": "GLM-5",
      "company": "Zhipu AI",
      "rank": 8,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        17.3,
        17.2,
        17.1,
        19.6,
        19.7,
        20,
        20,
        20.5,
        20.29,
        20.53,
        20.8,
        30,
        30,
        51.19,
        36.59,
        36.64,
        36.64
      ],
      "pillar_scores": {
        "issue_resolution": 79.6,
        "code_generation": null,
        "agentic_coding": null,
        "scientific": null,
        "human_preference": 92.5
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 72.8,
        "swe_rebench_pass1": 42.1,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": null,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": 1456.0
      }
    },
    {
      "name": "Llama 4.05B",
      "company": "Meta",
      "rank": 9,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        50.66,
        0.0,
        0.0,
        0.0
      ],
      "pillar_scores": {},
      "source_count": 0,
      "raw_data": {}
    },
    {
      "name": "Mistral Large",
      "company": "Mistral",
      "rank": 10,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        49.92,
        0.0,
        7.8,
        7.8
      ],
      "pillar_scores": {},
      "source_count": 1,
      "raw_data": {
        "arena_code_elo": 1223.0
      }
    },
    {
      "name": "MiniMax M2",
      "company": "MiniMax",
      "rank": 10,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        49.38,
        14.24,
        29.88,
        29.88
      ],
      "pillar_scores": {},
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 61.0,
        "terminalbench_hard_pct": 30.0,
        "arena_code_elo": 1312.0
      }
    },
    {
      "name": "Cohere Command R+",
      "company": "Cohere",
      "rank": 12,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        48.84,
        0.0,
        0.0,
        0.0
      ],
      "pillar_scores": {},
      "source_count": 0,
      "raw_data": {}
    },
    {
      "name": "Grok 4.1",
      "company": "xAI",
      "rank": 5,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        48.29,
        36.84,
        44.52,
        44.52
      ],
      "pillar_scores": {},
      "source_count": 4,
      "raw_data": {
        "swe_rebench_pass1": 52.9,
        "livecodebench_pct": 80.2,
        "bigcodebench_pct": 35.8,
        "arena_code_elo": 1204.0
      }
    },
    {
      "name": "DeepSeek R1",
      "company": "DeepSeek",
      "rank": 6,
      "scores": [
        35.5,
        35.4,
        35.5,
        35.4,
        35,
        34.8,
        34.4,
        34.3,
        34.7,
        35,
        35.2,
        35,
        35,
        34.9,
        35.2,
        35.5,
        36.4,
        36.4,
        36.2,
        36.2,
        36.8,
        37,
        36.7,
        36.5,
        36.6,
        36.3,
        36.2,
        35.9,
        35.9,
        35.5,
        35.5,
        35,
        35,
        34.9,
        35.5,
        35.1,
        35.2,
        35.3,
        35.1,
        35.4,
        35.4,
        35.1,
        34.9,
        35.2,
        35.4,
        35.6,
        35.4,
        35.4,
        35.42,
        35.13,
        35.31,
        34.99,
        34.95,
        34.91,
        47.75,
        44.0,
        44.0,
        44.0
      ],
      "pillar_scores": {
        "issue_resolution": 41,
        "code_generation": 95.6,
        "agentic_coding": null,
        "scientific": 42.6,
        "human_preference": null
      },
      "source_count": 4,
      "raw_data": {
        "swebench_verified_pct": null,
        "swe_rebench_pass1": 21.7,
        "livecodebench_pct": 73.1,
        "bigcodebench_pct": 40.5,
        "terminalbench_hard_pct": null,
        "swebench_pro_pct": null,
        "scicode_pct": 4.6,
        "arena_code_elo": null
      }
    },
    {
      "name": "Llama 4.08B",
      "company": "Meta",
      "rank": 12,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        47.21,
        24.53,
        24.53,
        24.53
      ],
      "pillar_scores": {},
      "source_count": 2,
      "raw_data": {
        "swe_rebench_pass1": 46.7,
        "livecodebench_pct": 69.8
      }
    },
    {
      "name": "Gemini Flash 3",
      "company": "Google",
      "rank": 14,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        46.67,
        3.16,
        7.29,
        7.29
      ],
      "pillar_scores": {},
      "source_count": 2,
      "raw_data": {
        "swebench_verified_pct": 13.52,
        "terminalbench_hard_pct": 17.1
      }
    },
    {
      "name": "Qwen3",
      "company": "Alibaba",
      "rank": 17,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        46.13,
        0.0,
        3.73,
        3.73
      ],
      "pillar_scores": {},
      "source_count": 1,
      "raw_data": {
        "swebench_pro_pct": 21.41
      }
    },
    {
      "name": "Mistral Voxtral",
      "company": "Mistral",
      "rank": 18,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        45.59,
        0.0,
        0.0,
        0.0
      ],
      "pillar_scores": {},
      "source_count": 0,
      "raw_data": {}
    },
    {
      "name": "GLM-4",
      "company": "Zhipu AI",
      "rank": 13,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        45.05,
        12.66,
        23.0,
        23.0
      ],
      "pillar_scores": {},
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 54.2,
        "swebench_pro_pct": 9.67,
        "arena_code_elo": 1356.0
      }
    },
    {
      "name": "MiniMax M1",
      "company": "MiniMax",
      "rank": 20,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        44.51,
        0.0,
        0.0,
        0.0
      ],
      "pillar_scores": {},
      "source_count": 0,
      "raw_data": {}
    },
    {
      "name": "Cohere Aya",
      "company": "Cohere",
      "rank": 21,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        43.97,
        0.0,
        0.0,
        0.0
      ],
      "pillar_scores": {},
      "source_count": 0,
      "raw_data": {}
    },
    {
      "name": "Llama 4.0",
      "company": "Meta",
      "rank": 22,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        43.43,
        0.0,
        0.0,
        0.0
      ],
      "pillar_scores": {},
      "source_count": 0,
      "raw_data": {}
    }
  ]
}