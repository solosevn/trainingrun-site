{
  "formula_version": "1.0",
  "checksum": "3ac7c07d474006d25dff819be1281f2efe4541d74a41b2326e58148646fc21cd",
  "weights": {
    "swebench_verified": 0.17,
    "swe_rebench": 0.13,
    "livecodebench": 0.15,
    "bigcodebench": 0.1,
    "terminal_bench_hard": 0.12,
    "swebench_pro": 0.08,
    "scicode": 0.15,
    "arena_code_elo": 0.1
  },
  "dates": [
    "2026-01-01",
    "2026-01-02",
    "2026-01-03",
    "2026-01-04",
    "2026-01-05",
    "2026-01-06",
    "2026-01-07",
    "2026-01-08",
    "2026-01-09",
    "2026-01-10",
    "2026-01-11",
    "2026-01-12",
    "2026-01-13",
    "2026-01-14",
    "2026-01-15",
    "2026-01-16",
    "2026-01-17",
    "2026-01-18",
    "2026-01-19",
    "2026-01-20",
    "2026-01-21",
    "2026-01-22",
    "2026-01-23",
    "2026-01-24",
    "2026-01-25",
    "2026-01-26",
    "2026-01-27",
    "2026-01-28",
    "2026-01-29",
    "2026-01-30",
    "2026-01-31",
    "2026-02-01",
    "2026-02-02",
    "2026-02-03",
    "2026-02-04",
    "2026-02-05",
    "2026-02-06",
    "2026-02-07",
    "2026-02-08",
    "2026-02-09",
    "2026-02-10",
    "2026-02-11",
    "2026-02-12",
    "2026-02-13",
    "2026-02-14"
  ],
  "models": [
    {
      "name": "Claude Opus 4.5",
      "company": "Anthropic",
      "rank": 1,
      "scores": [
        63.2,
        63.4,
        63.1,
        63.4,
        63.2,
        63.5,
        63.5,
        63.0,
        63.5,
        63.3,
        63.3,
        63.3,
        63.5,
        63.4,
        63.4,
        63.3,
        62.6,
        63.2,
        63.3,
        63.4,
        63.2,
        63.4,
        63.5,
        63.5,
        63.1,
        63.3,
        63.5,
        63.0,
        63.6,
        63.5,
        63.5,
        63.0,
        63.3,
        63.3,
        63.3,
        63.7,
        63.3,
        63.1,
        63.3,
        63.4,
        63.2,
        63.0,
        63.3,
        63.4,
        63.3
      ],
      "pillar_scores": {
        "issue_resolution": 88.6,
        "code_generation": 58.5,
        "agentic_coding": 92.0,
        "scientific": null,
        "human_preference": 95.9
      },
      "source_count": 4,
      "raw_data": {
        "swebench_verified_pct": 74.4,
        "swe_rebench_pass1": 43.8,
        "livecodebench_pct": 46.9,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 63.1,
        "swebench_pro_pct": 45.89,
        "scicode_pct": null,
        "arena_code_elo": 1503
      }
    },
    {
      "name": "Claude Sonnet 4.5",
      "company": "Anthropic",
      "rank": 2,
      "scores": [
        59.6,
        59.9,
        59.5,
        59.8,
        59.8,
        60.0,
        59.9,
        59.2,
        59.6,
        59.8,
        59.0,
        59.6,
        59.3,
        59.8,
        59.6,
        59.4,
        59.4,
        59.4,
        59.7,
        60.0,
        59.6,
        59.5,
        59.7,
        59.8,
        59.9,
        59.4,
        59.3,
        59.7,
        59.4,
        59.2,
        59.6,
        59.7,
        59.4,
        59.6,
        59.5,
        59.6,
        59.7,
        59.8,
        59.5,
        59.7,
        59.6,
        59.5,
        59.4,
        59.4,
        59.5
      ],
      "pillar_scores": {
        "issue_resolution": 89.3,
        "code_generation": 58.7,
        "agentic_coding": 78.5,
        "scientific": null,
        "human_preference": 88.7
      },
      "source_count": 4,
      "raw_data": {
        "swebench_verified_pct": 70.6,
        "swe_rebench_pass1": 47.1,
        "livecodebench_pct": 47.1,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 46.5,
        "swebench_pro_pct": 43.6,
        "scicode_pct": null,
        "arena_code_elo": 1390
      }
    },
    {
      "name": "Gemini 3 Pro",
      "company": "Google",
      "rank": 3,
      "scores": [
        55.6,
        55.1,
        55.1,
        55.4,
        55.2,
        55.4,
        55.5,
        55.2,
        55.6,
        54.9,
        55.2,
        55.7,
        55.8,
        55.3,
        55.2,
        55.3,
        55.1,
        55.5,
        55.1,
        55.9,
        54.9,
        55.5,
        55.5,
        54.9,
        55.6,
        54.9,
        55.8,
        55.4,
        55.0,
        55.4,
        55.3,
        55.0,
        55.2,
        54.9,
        55.5,
        55.4,
        55.2,
        55.4,
        55.5,
        55.6,
        55.4,
        55.5,
        55.2,
        55.3,
        55.3
      ],
      "pillar_scores": {
        "issue_resolution": 93.3,
        "code_generation": null,
        "agentic_coding": 90.3,
        "scientific": null,
        "human_preference": 92.5
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 77.4,
        "swe_rebench_pass1": 46.7,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 64.7,
        "swebench_pro_pct": 43.3,
        "scicode_pct": null,
        "arena_code_elo": 1449
      }
    },
    {
      "name": "GPT-5.2",
      "company": "OpenAI",
      "rank": 4,
      "scores": [
        53.3,
        52.4,
        53.2,
        53.2,
        52.7,
        53.3,
        53.5,
        53.3,
        53.1,
        53.0,
        52.7,
        53.2,
        53.1,
        53.6,
        53.0,
        53.1,
        53.2,
        53.7,
        53.3,
        53.2,
        53.3,
        53.3,
        53.1,
        53.3,
        53.2,
        53.1,
        53.1,
        53.6,
        53.3,
        53.1,
        53.5,
        53.3,
        53.1,
        53.2,
        53.2,
        53.2,
        53.4,
        53.1,
        53.1,
        53.3,
        53.3,
        53.2,
        53.1,
        53.2,
        53.2
      ],
      "pillar_scores": {
        "issue_resolution": 94.4,
        "code_generation": null,
        "agentic_coding": 75.8,
        "scientific": null,
        "human_preference": 94.0
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 71.8,
        "swe_rebench_pass1": 51.7,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 64.9,
        "swebench_pro_pct": 29.94,
        "scicode_pct": null,
        "arena_code_elo": 1473
      }
    },
    {
      "name": "Claude Opus 4.6",
      "company": "Anthropic",
      "rank": 5,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        49.9,
        50.0,
        50.0,
        50.0,
        49.8,
        49.8,
        49.9,
        50.1,
        50.0,
        49.9
      ],
      "pillar_scores": {
        "issue_resolution": 96.1,
        "code_generation": null,
        "agentic_coding": 93.1,
        "scientific": null,
        "human_preference": 100.0
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 74.4,
        "swe_rebench_pass1": 51.7,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 69.9,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": 1567
      }
    },
    {
      "name": "Gemini 2.5 Pro",
      "company": "Google",
      "rank": 6,
      "scores": [
        46.9,
        47.1,
        47.3,
        47.1,
        47.3,
        47.2,
        47.3,
        47.2,
        47.5,
        47.5,
        47.5,
        47.3,
        47.5,
        47.1,
        47.1,
        47.2,
        46.9,
        47.3,
        47.5,
        47.1,
        47.3,
        47.2,
        47.3,
        47.4,
        47.3,
        47.2,
        47.5,
        47.2,
        47.3,
        47.1,
        47.5,
        47.7,
        47.3,
        47.5,
        47.2,
        46.9,
        47.0,
        47.3,
        47.2,
        47.2,
        47.3,
        47.3,
        47.4,
        47.2,
        47.3
      ],
      "pillar_scores": {
        "issue_resolution": 68.0,
        "code_generation": 90.9,
        "agentic_coding": 43.4,
        "scientific": null,
        "human_preference": 77.1
      },
      "source_count": 4,
      "raw_data": {
        "swebench_verified_pct": 53.6,
        "swe_rebench_pass1": null,
        "livecodebench_pct": 73.6,
        "bigcodebench_pct": 36.5,
        "terminalbench_hard_pct": 32.6,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": 1208
      }
    },
    {
      "name": "GPT-5.1",
      "company": "OpenAI",
      "rank": 7,
      "scores": [
        42.4,
        42.8,
        42.6,
        42.5,
        42.8,
        42.6,
        42.5,
        42.5,
        42.3,
        42.3,
        42.7,
        42.6,
        42.5,
        42.7,
        42.4,
        42.3,
        42.7,
        42.6,
        42.6,
        42.6,
        42.5,
        42.6,
        42.5,
        42.8,
        42.8,
        42.8,
        42.7,
        42.5,
        42.4,
        42.6,
        42.8,
        42.7,
        42.4,
        42.4,
        42.6,
        42.7,
        42.8,
        42.5,
        42.4,
        42.7,
        42.6,
        42.5,
        42.6,
        42.7,
        42.6
      ],
      "pillar_scores": {
        "issue_resolution": 87.7,
        "code_generation": null,
        "agentic_coding": 63.4,
        "scientific": null,
        "human_preference": 88.7
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 66.0,
        "swe_rebench_pass1": 48.5,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 47.6,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": 1390
      }
    },
    {
      "name": "Qwen3-Coder-480B",
      "company": "Alibaba",
      "rank": 8,
      "scores": [
        42.3,
        42.0,
        41.9,
        42.5,
        42.2,
        42.7,
        42.1,
        42.0,
        41.9,
        42.2,
        42.6,
        41.8,
        42.0,
        41.8,
        42.2,
        41.9,
        41.9,
        42.2,
        42.1,
        42.1,
        41.9,
        42.1,
        42.1,
        42.3,
        42.1,
        42.0,
        42.4,
        42.3,
        41.9,
        41.9,
        41.9,
        42.2,
        42.0,
        42.0,
        42.0,
        42.0,
        42.0,
        42.1,
        42.2,
        42.0,
        42.2,
        42.0,
        42.1,
        42.1,
        42.1
      ],
      "pillar_scores": {
        "issue_resolution": 74.1,
        "code_generation": null,
        "agentic_coding": 60.3,
        "scientific": null,
        "human_preference": 81.9
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 69.6,
        "swe_rebench_pass1": 31.7,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 27.2,
        "swebench_pro_pct": 38.7,
        "scicode_pct": null,
        "arena_code_elo": 1284
      }
    },
    {
      "name": "DeepSeek V3.2",
      "company": "DeepSeek",
      "rank": 9,
      "scores": [
        40.1,
        40.0,
        39.8,
        40.2,
        39.9,
        40.1,
        40.1,
        39.8,
        40.0,
        40.2,
        40.0,
        40.3,
        40.1,
        39.8,
        40.1,
        39.9,
        40.0,
        39.8,
        39.8,
        40.1,
        39.8,
        39.8,
        40.1,
        39.9,
        40.1,
        40.1,
        39.9,
        40.1,
        39.9,
        39.7,
        39.9,
        39.7,
        39.9,
        39.7,
        40.0,
        40.1,
        39.9,
        40.0,
        39.8,
        40.0,
        40.0,
        40.1,
        40.0,
        40.2,
        40.0
      ],
      "pillar_scores": {
        "issue_resolution": 73.5,
        "code_generation": null,
        "agentic_coding": 43.3,
        "scientific": null,
        "human_preference": 87.7
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 60.0,
        "swe_rebench_pass1": 37.5,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 39.6,
        "swebench_pro_pct": 15.56,
        "scicode_pct": null,
        "arena_code_elo": 1375
      }
    },
    {
      "name": "GPT-5",
      "company": "OpenAI",
      "rank": 10,
      "scores": [
        39.6,
        40.2,
        39.5,
        39.9,
        39.4,
        39.7,
        39.3,
        39.5,
        39.6,
        39.3,
        39.6,
        39.7,
        39.6,
        39.5,
        39.6,
        39.5,
        39.8,
        39.4,
        39.7,
        39.5,
        39.6,
        39.2,
        39.4,
        40.0,
        39.5,
        39.8,
        39.5,
        39.9,
        39.6,
        39.6,
        39.5,
        39.7,
        39.7,
        39.5,
        39.7,
        39.6,
        39.7,
        39.5,
        39.5,
        39.7,
        39.3,
        39.6,
        39.5,
        39.5,
        39.6
      ],
      "pillar_scores": {
        "issue_resolution": 91.1,
        "code_generation": null,
        "agentic_coding": 78.5,
        "scientific": null,
        "human_preference": 89.0
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 71.8,
        "swe_rebench_pass1": null,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 49.6,
        "swebench_pro_pct": 41.78,
        "scicode_pct": null,
        "arena_code_elo": 1395
      }
    },
    {
      "name": "Kimi K2 Thinking",
      "company": "Moonshot AI",
      "rank": 11,
      "scores": [
        38.6,
        38.9,
        38.6,
        38.7,
        38.6,
        38.7,
        38.4,
        38.9,
        38.9,
        38.3,
        38.8,
        38.5,
        38.6,
        38.6,
        38.3,
        38.7,
        38.4,
        38.8,
        38.7,
        38.5,
        38.7,
        38.9,
        39.0,
        38.6,
        38.9,
        38.7,
        38.5,
        38.9,
        38.7,
        38.9,
        38.5,
        38.7,
        38.7,
        38.9,
        38.8,
        38.8,
        38.9,
        38.7,
        38.8,
        38.7,
        38.6,
        38.8,
        38.8,
        38.7,
        38.7
      ],
      "pillar_scores": {
        "issue_resolution": 81.6,
        "code_generation": null,
        "agentic_coding": 47.5,
        "scientific": null,
        "human_preference": 85.3
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 63.4,
        "swe_rebench_pass1": 43.8,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 35.7,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": 1336
      }
    },
    {
      "name": "GLM-4.6",
      "company": "Zhipu AI",
      "rank": 12,
      "scores": [
        37.8,
        38.3,
        38.4,
        38.2,
        37.9,
        38.4,
        37.7,
        38.2,
        37.9,
        37.9,
        37.9,
        37.8,
        37.7,
        38.0,
        37.9,
        38.1,
        38.2,
        38.2,
        37.7,
        37.8,
        38.1,
        38.1,
        38.1,
        38.1,
        38.2,
        38.3,
        37.8,
        38.3,
        38.1,
        38.2,
        38.0,
        37.9,
        38.0,
        38.2,
        38.3,
        37.9,
        38.1,
        38.0,
        38.2,
        38.3,
        38.2,
        38.3,
        38.2,
        38.0,
        38.1
      ],
      "pillar_scores": {
        "issue_resolution": 78.3,
        "code_generation": null,
        "agentic_coding": 26.8,
        "scientific": null,
        "human_preference": 86.7
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 68.2,
        "swe_rebench_pass1": 37.1,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 24.5,
        "swebench_pro_pct": 9.67,
        "scicode_pct": null,
        "arena_code_elo": 1358
      }
    },
    {
      "name": "Gemini 3 Flash",
      "company": "Google",
      "rank": 13,
      "scores": [
        37.2,
        37.0,
        36.9,
        36.8,
        37.0,
        36.9,
        37.3,
        37.3,
        36.5,
        37.0,
        37.1,
        37.0,
        36.8,
        37.0,
        37.0,
        37.2,
        37.3,
        37.1,
        37.0,
        37.3,
        37.3,
        37.1,
        37.0,
        37.0,
        37.2,
        37.1,
        37.0,
        36.9,
        36.9,
        36.9,
        37.2,
        37.0,
        36.9,
        36.9,
        37.0,
        36.9,
        36.9,
        37.0,
        37.1,
        37.1,
        36.9,
        37.1,
        36.9,
        37.0,
        37.0
      ],
      "pillar_scores": {
        "issue_resolution": 88.3,
        "code_generation": null,
        "agentic_coding": 80.5,
        "scientific": null,
        "human_preference": 92.2
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": null,
        "swe_rebench_pass1": 46.7,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 64.3,
        "swebench_pro_pct": 34.63,
        "scicode_pct": null,
        "arena_code_elo": 1444
      }
    },
    {
      "name": "DeepSeek R1",
      "company": "DeepSeek",
      "rank": 14,
      "scores": [
        35.2,
        35.1,
        35.3,
        35.3,
        35.4,
        35.4,
        35.2,
        35.4,
        35.4,
        35.4,
        35.7,
        35.4,
        35.2,
        35.4,
        35.4,
        35.3,
        35.2,
        35.3,
        35.3,
        35.3,
        35.7,
        35.3,
        35.1,
        35.4,
        35.4,
        35.4,
        35.5,
        35.4,
        35.3,
        35.4,
        35.4,
        35.4,
        35.4,
        35.3,
        35.4,
        35.4,
        35.3,
        35.4,
        35.5,
        35.3,
        35.3,
        35.4,
        35.4,
        35.4,
        35.4
      ],
      "pillar_scores": {
        "issue_resolution": 41.0,
        "code_generation": 95.6,
        "agentic_coding": null,
        "scientific": 42.6,
        "human_preference": null
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": null,
        "swe_rebench_pass1": 21.7,
        "livecodebench_pct": 73.1,
        "bigcodebench_pct": 40.5,
        "terminalbench_hard_pct": null,
        "swebench_pro_pct": null,
        "scicode_pct": 4.6,
        "arena_code_elo": null
      }
    },
    {
      "name": "Claude Sonnet 4",
      "company": "Anthropic",
      "rank": 15,
      "scores": [
        33.3,
        33.5,
        33.4,
        33.6,
        33.6,
        33.6,
        33.8,
        33.6,
        33.4,
        33.5,
        33.8,
        33.5,
        33.7,
        33.3,
        33.4,
        33.5,
        33.5,
        33.2,
        33.5,
        33.5,
        33.3,
        33.5,
        33.5,
        33.6,
        33.7,
        33.5,
        33.3,
        33.5,
        33.6,
        33.3,
        33.4,
        33.4,
        33.4,
        33.4,
        33.4,
        33.3,
        33.4,
        33.6,
        33.5,
        33.6,
        33.5,
        33.6,
        33.6,
        33.4,
        33.5
      ],
      "pillar_scores": {
        "issue_resolution": 91.9,
        "code_generation": 69.7,
        "agentic_coding": 93.0,
        "scientific": null,
        "human_preference": null
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 72.4,
        "swe_rebench_pass1": null,
        "livecodebench_pct": 55.9,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": null,
        "swebench_pro_pct": 42.7,
        "scicode_pct": null,
        "arena_code_elo": null
      }
    },
    {
      "name": "Claude Haiku 4.5",
      "company": "Anthropic",
      "rank": 16,
      "scores": [
        29.4,
        29.3,
        29.7,
        29.6,
        29.6,
        29.6,
        29.9,
        29.6,
        29.5,
        29.7,
        29.5,
        29.7,
        29.6,
        29.6,
        29.6,
        29.7,
        29.5,
        29.5,
        29.7,
        29.6,
        29.7,
        29.7,
        29.5,
        29.7,
        29.5,
        29.6,
        29.6,
        29.5,
        29.5,
        29.6,
        29.7,
        29.7,
        29.6,
        29.8,
        29.8,
        29.6,
        29.7,
        29.6,
        29.6,
        29.6,
        29.6,
        29.6,
        29.6,
        29.6,
        29.6
      ],
      "pillar_scores": {
        "issue_resolution": 51.5,
        "code_generation": null,
        "agentic_coding": 66.6,
        "scientific": null,
        "human_preference": 83.4
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": 40.6,
        "swe_rebench_pass1": null,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 35.5,
        "swebench_pro_pct": 39.45,
        "scicode_pct": null,
        "arena_code_elo": 1307
      }
    },
    {
      "name": "MiniMax M2.1",
      "company": "MiniMax",
      "rank": 17,
      "scores": [
        28.9,
        28.9,
        29.0,
        29.0,
        29.3,
        28.9,
        28.9,
        29.2,
        29.0,
        29.1,
        29.1,
        29.3,
        29.0,
        29.0,
        29.0,
        28.8,
        29.1,
        29.0,
        29.2,
        29.2,
        29.0,
        29.1,
        28.8,
        29.1,
        29.0,
        29.2,
        29.0,
        29.1,
        29.0,
        28.9,
        29.1,
        29.0,
        28.9,
        29.0,
        29.0,
        29.1,
        29.0,
        29.0,
        29.1,
        29.0,
        29.0,
        28.9,
        29.0,
        29.0,
        29.0
      ],
      "pillar_scores": {
        "issue_resolution": 59.9,
        "code_generation": null,
        "agentic_coding": 64.5,
        "scientific": null,
        "human_preference": 89.8
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": null,
        "swe_rebench_pass1": 31.7,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 36.6,
        "swebench_pro_pct": 36.81,
        "scicode_pct": null,
        "arena_code_elo": 1407
      }
    },
    {
      "name": "Devstral 2",
      "company": "Mistral",
      "rank": 18,
      "scores": [
        28.1,
        28.5,
        28.5,
        28.4,
        28.4,
        28.5,
        28.2,
        28.7,
        28.3,
        28.3,
        28.7,
        28.4,
        28.6,
        28.8,
        28.1,
        28.4,
        28.5,
        28.5,
        28.5,
        28.6,
        28.6,
        28.5,
        28.6,
        28.3,
        28.3,
        28.5,
        28.3,
        28.4,
        28.7,
        28.5,
        28.4,
        28.5,
        28.5,
        28.6,
        28.7,
        28.6,
        28.5,
        28.3,
        28.6,
        28.5,
        28.6,
        28.5,
        28.4,
        28.3,
        28.5
      ],
      "pillar_scores": {
        "issue_resolution": 69.6,
        "code_generation": null,
        "agentic_coding": null,
        "scientific": null,
        "human_preference": 76.6
      },
      "source_count": 2,
      "raw_data": {
        "swebench_verified_pct": 53.8,
        "swe_rebench_pass1": 37.5,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": null,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": 1201
      }
    },
    {
      "name": "GPT-5 Mini",
      "company": "OpenAI",
      "rank": 19,
      "scores": [
        27.0,
        26.9,
        27.0,
        27.1,
        27.0,
        27.0,
        27.1,
        26.7,
        27.2,
        27.0,
        27.1,
        27.2,
        27.3,
        27.1,
        27.1,
        26.8,
        27.1,
        27.2,
        27.1,
        27.2,
        27.3,
        27.2,
        27.1,
        26.9,
        27.2,
        27.3,
        26.9,
        27.1,
        27.2,
        27.0,
        27.1,
        27.0,
        27.3,
        27.0,
        27.1,
        27.2,
        27.1,
        27.1,
        27.1,
        27.2,
        27.1,
        27.2,
        27.1,
        27.1,
        27.1
      ],
      "pillar_scores": {
        "issue_resolution": 71.0,
        "code_generation": null,
        "agentic_coding": 46.3,
        "scientific": null,
        "human_preference": null
      },
      "source_count": 2,
      "raw_data": {
        "swebench_verified_pct": 59.8,
        "swe_rebench_pass1": 35.0,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 34.8,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": null
      }
    },
    {
      "name": "Kimi K2 Instruct",
      "company": "Moonshot AI",
      "rank": 20,
      "scores": [
        26.9,
        26.8,
        26.8,
        27.1,
        26.9,
        26.9,
        27.0,
        26.9,
        27.2,
        26.9,
        27.0,
        27.1,
        27.0,
        27.2,
        27.1,
        27.0,
        27.2,
        27.1,
        27.1,
        27.1,
        27.2,
        27.0,
        27.2,
        27.2,
        27.0,
        27.0,
        27.0,
        27.1,
        27.2,
        27.2,
        27.1,
        26.9,
        27.0,
        26.9,
        27.0,
        27.0,
        27.1,
        27.0,
        27.1,
        27.0,
        27.3,
        27.1,
        27.1,
        27.1,
        27.1
      ],
      "pillar_scores": {
        "issue_resolution": 60.2,
        "code_generation": null,
        "agentic_coding": 48.7,
        "scientific": null,
        "human_preference": null
      },
      "source_count": 2,
      "raw_data": {
        "swebench_verified_pct": 43.8,
        "swe_rebench_pass1": 34.3,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 27.8,
        "swebench_pro_pct": 27.67,
        "scicode_pct": null,
        "arena_code_elo": null
      }
    },
    {
      "name": "Claude Opus 4",
      "company": "Anthropic",
      "rank": 21,
      "scores": [
        26.6,
        26.5,
        26.4,
        26.5,
        26.3,
        26.2,
        26.4,
        26.8,
        26.3,
        26.4,
        26.2,
        26.4,
        26.3,
        26.6,
        26.4,
        26.4,
        26.1,
        26.3,
        26.2,
        26.3,
        26.2,
        26.4,
        26.4,
        26.4,
        26.5,
        26.6,
        26.3,
        26.5,
        26.4,
        26.5,
        26.4,
        26.3,
        26.6,
        26.4,
        26.3,
        26.3,
        26.3,
        26.5,
        26.6,
        26.4,
        26.5,
        26.4,
        26.4,
        26.4,
        26.4
      ],
      "pillar_scores": {
        "issue_resolution": 92.9,
        "code_generation": 70.6,
        "agentic_coding": null,
        "scientific": null,
        "human_preference": null
      },
      "source_count": 2,
      "raw_data": {
        "swebench_verified_pct": 73.2,
        "swe_rebench_pass1": null,
        "livecodebench_pct": 56.6,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": null,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": null
      }
    },
    {
      "name": "Kimi K2.5",
      "company": "Moonshot AI",
      "rank": 22,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        25.4,
        25.7,
        25.6,
        25.5,
        25.4,
        25.5,
        25.5,
        25.3,
        25.5,
        25.4,
        25.6,
        25.4,
        25.6,
        25.5,
        25.5,
        25.4,
        25.5,
        25.5,
        25.5
      ],
      "pillar_scores": {
        "issue_resolution": 71.6,
        "code_generation": null,
        "agentic_coding": 57.5,
        "scientific": null,
        "human_preference": 92.3
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": null,
        "swe_rebench_pass1": 37.9,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 43.2,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": 1447
      }
    },
    {
      "name": "GLM-4.7",
      "company": "Zhipu AI",
      "rank": 23,
      "scores": [
        25.0,
        24.7,
        24.7,
        24.5,
        24.5,
        24.8,
        24.7,
        25.0,
        24.6,
        25.0,
        24.9,
        24.9,
        25.1,
        24.8,
        24.5,
        24.9,
        24.6,
        24.8,
        24.6,
        24.9,
        24.7,
        24.7,
        24.7,
        24.7,
        24.9,
        24.8,
        24.7,
        24.7,
        24.6,
        24.7,
        24.8,
        24.7,
        24.8,
        24.7,
        24.7,
        24.7,
        24.7,
        24.6,
        24.7,
        24.6,
        24.7,
        24.7,
        24.7,
        24.8,
        24.7
      ],
      "pillar_scores": {
        "issue_resolution": 78.1,
        "code_generation": null,
        "agentic_coding": 44.5,
        "scientific": null,
        "human_preference": 92.0
      },
      "source_count": 3,
      "raw_data": {
        "swebench_verified_pct": null,
        "swe_rebench_pass1": 41.3,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 33.4,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": 1442
      }
    },
    {
      "name": "GLM-5",
      "company": "Zhipu AI",
      "rank": 24,
      "scores": [
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        null,
        19.6,
        19.6,
        19.7,
        19.6
      ],
      "pillar_scores": {
        "issue_resolution": 79.6,
        "code_generation": null,
        "agentic_coding": null,
        "scientific": null,
        "human_preference": 92.5
      },
      "source_count": 2,
      "raw_data": {
        "swebench_verified_pct": null,
        "swe_rebench_pass1": 42.1,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": null,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": 1449
      }
    },
    {
      "name": "Claude Opus 4.1",
      "company": "Anthropic",
      "rank": 25,
      "scores": [
        15.1,
        14.7,
        15.0,
        14.8,
        15.0,
        15.1,
        14.9,
        14.7,
        15.1,
        14.9,
        14.8,
        14.8,
        15.0,
        15.3,
        14.9,
        14.9,
        14.8,
        14.8,
        14.8,
        15.0,
        15.0,
        14.8,
        14.8,
        14.8,
        15.0,
        14.7,
        14.9,
        15.0,
        14.8,
        14.7,
        15.0,
        15.0,
        14.9,
        14.9,
        14.8,
        14.9,
        14.9,
        14.8,
        15.0,
        14.9,
        15.0,
        15.0,
        15.0,
        14.8,
        14.9
      ],
      "pillar_scores": {
        "issue_resolution": null,
        "code_generation": null,
        "agentic_coding": 50.6,
        "scientific": null,
        "human_preference": 88.8
      },
      "source_count": 2,
      "raw_data": {
        "swebench_verified_pct": null,
        "swe_rebench_pass1": null,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 38.0,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": 1391
      }
    },
    {
      "name": "Grok 4",
      "company": "xAI",
      "rank": 26,
      "scores": [
        12.0,
        12.2,
        12.4,
        12.3,
        12.6,
        12.3,
        12.1,
        11.8,
        12.4,
        12.2,
        12.2,
        12.1,
        12.0,
        12.2,
        12.2,
        11.8,
        12.1,
        12.2,
        11.9,
        12.2,
        12.2,
        12.3,
        12.0,
        12.4,
        12.1,
        12.0,
        12.2,
        12.4,
        12.2,
        12.3,
        12.3,
        12.4,
        12.0,
        12.2,
        12.2,
        12.1,
        12.4,
        12.1,
        12.2,
        12.2,
        12.2,
        12.3,
        12.1,
        12.3,
        12.2
      ],
      "pillar_scores": {
        "issue_resolution": null,
        "code_generation": null,
        "agentic_coding": 36.2,
        "scientific": null,
        "human_preference": 78.9
      },
      "source_count": 2,
      "raw_data": {
        "swebench_verified_pct": null,
        "swe_rebench_pass1": null,
        "livecodebench_pct": null,
        "bigcodebench_pct": null,
        "terminalbench_hard_pct": 27.2,
        "swebench_pro_pct": null,
        "scicode_pct": null,
        "arena_code_elo": 1237
      }
    }
  ]
}
