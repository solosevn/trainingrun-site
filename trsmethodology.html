<!DOCTYPE html>
<html lang="en">
<head>
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-20ZZ8BG99X"></script>
        <script>
                  window.dataLayer = window.dataLayer || [];
                  function gtag(){dataLayer.push(arguments);}
                  gtag('js', new Date());
                  gtag('config', 'G-20ZZ8BG99X');
        </script>
        </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TRS Methodology | Training Run</title>
    <meta name="description" content="The complete methodology behind the Training Run Score (TRS) - how we measure and rank AI model performance with full source citations.">
    <meta property="og:title" content="TRS Methodology | Training Run">
    <meta property="og:description" content="Transparent, fact-checked methodology for scoring AI models. Full source citations.">
    <link rel="canonical" href="https://trainingrun.ai/trsmethodology">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&family=Space+Grotesk:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="bg-animation"></div>
    <nav>
        <a href="/" class="logo">Training Run</a>
        <ul class="nav-links">
            <li><a href="/trsmethodology" class="active">TRS Methodology</a></li>
            <li><a href="/scores">Current Scores</a></li>
            <li><a href="/about">About</a></li>
        </ul>
    </nav>
    <a href="#" onclick="history.back(); return false;" class="back-btn"><svg viewBox="0 0 24 24"><path d="M19 12H5M12 19l-7-7 7-7"/></svg> Back</a>
    <article class="methodology-page">
        <header class="page-header">
            <h1>TRS <span class="cyan">Methodology</span></h1>
            <p class="page-intro">The Training Run Score (TRS) is a composite metric designed to provide a clear, comparable measure of AI model capabilities. This page documents our complete methodology with full source citations.</p>
            <p class="last-updated">Last Updated: February 11, 2026</p>
        </header>
        <section class="method-section">
            <h2>Executive Summary</h2>
            <div class="summary-box">
                <p>The TRS aggregates performance data from established benchmarks into a single 0-100 score. We weight seven dimensions based on their relevance to real-world AI utility:</p>
                <div class="formula-display">
                    <code>TRS = (S x 0.21) + (R x 0.20) + (C x 0.20) + (H x 0.18) + (K x 0.08) + (E x 0.07) + (U x 0.06)</code>
                </div>
                <p class="formula-note">Where S = Safety, R = Reasoning, C = Coding, H = Human Preference, K = Knowledge, E = Efficiency, U = Usage Adoption</p>
            </div>
        </section>
        <section class="method-section">
            <h2>1. Reasoning and Logic (20%)</h2>
            <div class="method-content">
                <h3>What We Measure</h3>
                <p>The ability to solve novel problems requiring multi-step reasoning, logical deduction, and genuine understanding.</p>
                <h3>Primary Data Sources</h3>
                <div class="source-citation">
                    <div class="source-item">
                        <h4>ARC-AGI-2 (ARC Prize Foundation)</h4>
                        <p>The Abstraction and Reasoning Corpus tests novel reasoning on tasks specifically designed to require thinking through new problems.</p>
                        <ul class="source-details">
                            <li><strong>Current best baseline:</strong> 31% accuracy</li>
                            <li><strong>With refinement loops:</strong> 54% accuracy</li>
                            <li><strong>Human average:</strong> 60% accuracy</li>
                        </ul>
                        <a href="https://arcprize.org/" target="_blank" rel="noopener" class="source-link">Source: arcprize.org</a>
                    </div>
                    <div class="source-item">
                        <h4>GPQA Diamond (NYU, Anthropic, et al.)</h4>
                        <p>Graduate-level science questions written by PhD experts.</p>
                        <a href="https://arxiv.org/abs/2311.12022" target="_blank" rel="noopener" class="source-link">Source: arXiv:2311.12022</a>
                    </div>
                    <div class="source-item">
                        <h4>MATH (Hendrycks et al.)</h4>
                        <p>Competition-level mathematics problems from AMC, AIME, and Olympiad competitions.</p>
                        <a href="https://arxiv.org/abs/2103.03874" target="_blank" rel="noopener" class="source-link">Source: arXiv:2103.03874</a>
                    </div>
                </div>
                <h3>Score Calculation</h3>
                <code class="calc-formula">R = (ARC x 0.40) + (GPQA x 0.35) + (MATH x 0.25)</code>
            </div>
        </section>
        <section class="method-section">
            <h2>2. Coding Proficiency (20%)</h2>
            <div class="method-content">
                <h3>What We Measure</h3>
                <p>Can this model actually write code that works? Real software engineering tasks that mirror what professional developers face daily.</p>
                <h3>Why This Matters for TRS</h3>
                <p>Coding ability is one of the clearest demonstrations of an AI model's practical intelligence. A model that can debug complex codebases, implement features across multiple files, and write maintainable code provides genuine utility.</p>
                <h3>Primary Data Sources</h3>
                <div class="source-citation">
                    <div class="source-item">
                        <h4>SWE-Bench Verified (50% of Coding Score)</h4>
                        <p>Percentage of real GitHub issues resolved correctly. These are actual bugs and feature requests from production repositories.</p>
                        <a href="https://www.swebench.com/" target="_blank" rel="noopener" class="source-link">Source: swebench.com</a>
                    </div>
                    <div class="source-item">
                        <h4>LiveCodeBench (25% of Coding Score)</h4>
                        <p>Performance on coding problems released after model training cutoffs. Eliminates benchmark contamination.</p>
                        <a href="https://livecodebench.github.io/" target="_blank" rel="noopener" class="source-link">Source: livecodebench.github.io</a>
                    </div>
                    <div class="source-item">
                        <h4>SciCode (15% of Coding Score)</h4>
                        <p>Ability to solve scientific research coding challenges.</p>
                        <a href="https://scicode-bench.github.io/" target="_blank" rel="noopener" class="source-link">Source: scicode-bench.github.io</a>
                    </div>
                    <div class="source-item">
                        <h4>Legacy Benchmarks (10% of Coding Score)</h4>
                        <p>HumanEval and MBPP measure basic coding competency on isolated function problems.</p>
                        <a href="https://arxiv.org/abs/2107.03374" target="_blank" rel="noopener" class="source-link">Source: arXiv:2107.03374 (HumanEval)</a>
                        <a href="https://arxiv.org/abs/2108.07732" target="_blank" rel="noopener" class="source-link">Source: arXiv:2108.07732 (MBPP)</a>
                    </div>
                </div>
                <h3>Score Calculation</h3>
                <code class="calc-formula">C = (C_SWE x 0.50) + (C_LCB x 0.25) + (C_SciCode x 0.15) + (C_Legacy x 0.10)</code>
                <p class="formula-note">Where: C_SWE = Normalized SWE-Bench Verified score, C_LCB = Normalized LiveCodeBench score, C_SciCode = Normalized SciCode score, C_Legacy = Average of normalized HumanEval and MBPP scores</p>
            </div>
        </section>
        <section class="method-section">
            <h2>3. Human Preference (18%)</h2>
            <div class="method-content">
                <h3>What We Measure</h3>
                <p>When real people compare model outputs side-by-side, which model do they actually like more? This captures helpfulness, clarity, tone, and instruction-following.</p>
                <h3>Why We Use LMSYS Chatbot Arena</h3>
                <p>We use LMSYS Chatbot Arena as our primary signal because it is the most widely adopted, transparent, and actively maintained open platform for live LLM comparisons.</p>
                <ul class="source-details">
                    <li><strong>Blind, pairwise voting:</strong> Users chat with two anonymous models and vote for the better response.</li>
                    <li><strong>Large-scale:</strong> Hundreds of thousands to over a million human preference votes.</li>
                    <li><strong>Elo rating system:</strong> Similar to chess, maintains stable relative rankings.</li>
                    <li><strong>Model-agnostic:</strong> Both proprietary and open-weight models evaluated equally.</li>
                </ul>
                <h3>Known Limitations</h3>
                <ul class="source-details">
                    <li><strong>Prompt and user bias:</strong> Skewed toward English and tech-savvy users.</li>
                    <li><strong>Style vs. substance:</strong> Style can influence wins.</li>
                    <li><strong>Elo nuances:</strong> Small gaps may not be statistically meaningful.</li>
                    <li><strong>Partial observability:</strong> Only aggregate ratings are public.</li>
                </ul>
                <h3>Primary Data Source</h3>
                <div class="source-citation">
                    <div class="source-item">
                        <h4>LMSYS Chatbot Arena (UC Berkeley, LMSYS Group)</h4>
                        <p>Live, web-based evaluation where users interact with two anonymous models and vote for the better response.</p>
                        <a href="https://huggingface.co/spaces/lmarena-ai/chatbot-arena/" target="_blank" rel="noopener" class="source-link">Source: huggingface.co/spaces/lmarena-ai/chatbot-arena</a>
                        <a href="https://arxiv.org/abs/2403.04132" target="_blank" rel="noopener" class="source-link">Methodology: arXiv:2403.04132</a>
                    </div>
                </div>
                <h3>Score Calculation</h3>
                <code class="calc-formula">H = ((Model_Elo - Min_Elo) / (Max_Elo - Min_Elo)) x 100</code>
                <p class="formula-note">Maps the lowest-rated model to 0, highest to 100. Human Preference contributes 18% of TRS.</p>
            </div>
        </section>
        <section class="method-section">
            <h2>4. Knowledge and Comprehension (8%)</h2>
            <div class="method-content">
                <h3>What We Measure</h3>
                <p>Breadth and depth of factual knowledge across academic domains.</p>
                <h3>Primary Data Sources</h3>
                <div class="source-citation">
                    <div class="source-item">
                        <h4>MMLU (Hendrycks et al.)</h4>
                        <p>57 subjects from STEM to humanities, 14,000+ questions.</p>
                        <a href="https://arxiv.org/abs/2009.03300" target="_blank" rel="noopener" class="source-link">Source: arXiv:2009.03300</a>
                    </div>
                    <div class="source-item">
                        <h4>TruthfulQA (Lin et al.)</h4>
                        <p>Tests whether models generate truthful answers.</p>
                        <a href="https://arxiv.org/abs/2109.07958" target="_blank" rel="noopener" class="source-link">Source: arXiv:2109.07958</a>
                    </div>
                </div>
                <h3>Score Calculation</h3>
                <code class="calc-formula">K = (MMLU x 0.70) + (TruthfulQA x 0.30)</code>
            </div>
        </section>
        <section class="method-section">
            <h2>5. Efficiency and Cost (7%)</h2>
            <div class="method-content">
                <h3>What We Measure</h3>
                <p>Performance per dollar.</p>
                <h3>Data Sources</h3>
                <div class="source-citation">
                    <div class="source-item">
                        <h4>API Pricing</h4>
                        <p>Official pricing from OpenAI, Anthropic, Google.</p>
                    </div>
                </div>
                <h3>Score Calculation</h3>
                <code class="calc-formula">E = (Average_Benchmark_Score / Cost_Per_1M_Tokens) x Normalization_Factor</code>
            </div>
        </section>
        <section class="method-section">
            <h2>6. Safety and Reliability (21%)</h2>
            <div class="method-content">
                <h3>What We Measure</h3>
                <p>Harm avoidance, fairness, misuse prevention, adversarial robustness, and company-level safety governance. Safety is weighted highest because responsible AI ensures progress does not derail due to unchecked risks, while maintaining strong weights on Reasoning and Coding to drive technological advancement.</p>
                <h3>Why Safety Is Weighted #1</h3>
                <p>Multiple independent, quantifiable benchmarks now exist to measure AI safety objectively. By weighting safety highest, TRS incentivizes the development of models that are both capable and responsible, enabling high abundance for all humanity without stifling innovation.</p>
                <h3>Sub-Component Breakdown</h3>
                <div class="source-citation">
                    <div class="source-item">
                        <h4>Harm Avoidance (40% of Safety Score)</h4>
                        <p>Source: HELM Safety (Stanford CRFM). Unified framework aggregating 5 sub-benchmarks across 24+ models with 0-1 normalized scores.</p>
                        <a href="https://crfm.stanford.edu/helm/safety/latest/" target="_blank" rel="noopener" class="source-link">crfm.stanford.edu/helm/safety</a>
                    </div>
                    <div class="source-item">
                        <h4>Fairness (30% of Safety Score)</h4>
                        <p>Source: TrustLLM. Comprehensive trustworthiness evaluation covering fairness, privacy, robustness, and ethical alignment across major LLMs.</p>
                        <a href="https://trustllmbenchmark.github.io/TrustLLM-Website/" target="_blank" rel="noopener" class="source-link">trustllmbenchmark.github.io</a>
                    </div>
                    <div class="source-item">
                        <h4>Misuse Prevention (20% of Safety Score)</h4>
                        <p>Source: MLCommons AI Luminate. Industry consortium standard testing 12 hazard categories with 24,000+ prompts per language.</p>
                        <a href="https://ailuminate.mlcommons.org/benchmarks/" target="_blank" rel="noopener" class="source-link">ailuminate.mlcommons.org/benchmarks</a>
                    </div>
                    <div class="source-item">
                        <h4>Governance (10% of Safety Score)</h4>
                        <p>Sources: AI Safety Index (expert-reviewed company-level safety practices, 35 indicators, A-F grades) and Enkrypt AI Leaderboard (NIST RMF + OWASP Top 10 aligned, 200+ models, continuously updated).</p>
                        <a href="https://futureoflife.org/ai-safety-index-winter-2025/" target="_blank" rel="noopener" class="source-link">futureoflife.org/ai-safety-index</a>
                        <a href="https://leaderboard.enkryptai.com/" target="_blank" rel="noopener" class="source-link">leaderboard.enkryptai.com</a>
                    </div>
                </div>
                <h3>Score Calculation</h3>
                <p><code class="calc-formula">S = (HELM_Safety x 0.40) + (TrustLLM x 0.30) + (AILuminate x 0.20) + (Governance x 0.10)</code></p>
            </div>
        </section>
        <section class="method-section">
            <h2>7. Usage Adoption (6%)</h2>
            <div class="method-content">
                <h3>What We Measure</h3>
                <p>Real-world adoption and developer usage patterns, measured by normalized token consumption share across models and providers.</p>
                <h3>Data Source</h3>
                <div class="source-citation">
                    <div class="source-item">
                        <h4>OpenRouter Rankings</h4>
                        <p>Token consumption data across 300+ models from 60+ providers. Normalized token share in key categories.</p>
                        <a href="https://openrouter.ai/rankings" target="_blank" rel="noopener" class="source-link">openrouter.ai/rankings</a>
                    </div>
                </div>
                <h3>Known Limitations</h3>
                <ul class="source-details">
                    <li><strong>Measures popularity, not quality</strong> - High usage does not equal high performance</li>
                    <li><strong>Platform selection bias</strong> - Reflects OpenRouter user base, not all AI usage</li>
                    <li><strong>Not independently auditable</strong> - Token data is self-reported by OpenRouter</li>
                </ul>
                <h3>Score Calculation</h3>
                <p><code class="calc-formula">U = (Model_Token_Share / Max_Token_Share) x 100</code></p>
            </div>
        </section>
        <section class="method-section">
            <h2>Important Limitations</h2>
            <div class="limitations-box">
                <h3>What TRS Does NOT Measure</h3>
                <ul>
                    <li><strong>Future capabilities:</strong> TRS measures current performance only</li>
                    <li><strong>AGI proximity:</strong> We make no claims about AGI</li>
                    <li><strong>Real-world deployment:</strong> Benchmark performance may differ from production</li>
                </ul>
                <h3>Known Biases</h3>
                <ul>
                    <li>English-language bias in most benchmarks</li>
                    <li>Potential training data contamination</li>
                    <li>Self-reported safety data from providers</li>
                </ul>
            </div>
        </section>
        <section class="method-section">
            <h2>Update Frequency</h2>
            <p>TRS scores are updated <strong>weekly</strong>, typically on Mondays.</p>
        </section>
        <section class="method-section">
            <h2>Full Citation List</h2>
            <div class="citations-list">
                <h3>Evaluation Platforms</h3>
                <ul>
                    <li>LMSYS Chatbot Arena: <a href="https://huggingface.co/spaces/lmarena-ai/chatbot-arena/" target="_blank" rel="noopener">huggingface.co/spaces/lmarena-ai/chatbot-arena</a></li>
                    <li>ARC Prize: <a href="https://arcprize.org/" target="_blank" rel="noopener">arcprize.org</a></li>
                    <li>SWE-Bench: <a href="https://www.swebench.com/" target="_blank" rel="noopener">swebench.com</a></li>
                    <li>LiveCodeBench: <a href="https://livecodebench.github.io/" target="_blank" rel="noopener">livecodebench.github.io</a></li>
                    <li>SciCode: <a href="https://scicode-bench.github.io/" target="_blank" rel="noopener">scicode-bench.github.io</a></li>
                </ul>
                <h3>Safety Benchmarks</h3>
                <ul>
                    <li>HELM Safety (Stanford CRFM): <a href="https://crfm.stanford.edu/helm/safety/latest/" target="_blank" rel="noopener">crfm.stanford.edu/helm/safety</a></li>
                    <li>TrustLLM: <a href="https://trustllmbenchmark.github.io/TrustLLM-Website/" target="_blank" rel="noopener">trustllmbenchmark.github.io</a></li>
                    <li>MLCommons AI Luminate: <a href="https://ailuminate.mlcommons.org/benchmarks/" target="_blank" rel="noopener">ailuminate.mlcommons.org/benchmarks</a></li>
                    <li>AI Safety Index (FLI): <a href="https://futureoflife.org/ai-safety-index-winter-2025/" target="_blank" rel="noopener">futureoflife.org/ai-safety-index</a></li>
                    <li>Enkrypt AI Leaderboard: <a href="https://leaderboard.enkryptai.com/" target="_blank" rel="noopener">leaderboard.enkryptai.com</a></li>
                </ul>
                <h3>Usage Adoption</h3>
                <ul>
                    <li>OpenRouter Rankings: <a href="https://openrouter.ai/rankings" target="_blank" rel="noopener">openrouter.ai/rankings</a></li>
                </ul>
                <h3>Efficiency and Pricing</h3>
                <ul>
                    <li>Artificial Analysis: <a href="https://artificialanalysis.ai/" target="_blank" rel="noopener">artificialanalysis.ai</a></li>
                </ul>
            </div>
        </section>
    </article>
    <footer>
        <div class="container">
            <div class="footer-content">
                <div class="footer-brand">
                    <a href="/" class="logo">Training Run</a>
                    <p>Your weekly AI conditioning.</p>
                </div>
                <div class="footer-links">
                    <h4>Resources</h4>
                    <a href="/trsmethodology">TRS Methodology</a>
                    <a href="/scores">Current Scores</a>
                    <a href="/about">About Us</a>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2026 Training Run. All rights reserved.</p>
            </div>
        </div>
    </footer>
</body>
</html>
